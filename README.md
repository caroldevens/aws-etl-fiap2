# Tech Challenge FIAP â€” Fase 2  
## Pipeline Batch B3 na AWS (S3 + Glue + Lambda + Athena) â€” Raw â†’ Refined em Parquet

Este repositÃ³rio implementa um pipeline **batch** para coletar dados diÃ¡rios de aÃ§Ãµes da B3, armazenar em um **Data Lake no S3** (camadas **raw** e **refined**), executar transformaÃ§Ãµes no **AWS Glue (PySpark)**, acionar o fluxo via **S3 â†’ Lambda â†’ Glue**, **catalogar no Glue Data Catalog** e consultar via **SQL no Amazon Athena**.

---

## âœ… Requisitos do Pipeline (mapeamento 1:1 com o enunciado)

| Requisito | Como atendemos |
|---|---|
| **R1** â€“ Coletar dados de aÃ§Ãµes/Ã­ndices B3 (granularidade diÃ¡ria) | Glue Job `src/b3_collector.py` coleta via `yfinance` (dados diÃ¡rios) |
| **R2** â€“ Ingerir dados brutos no S3 em Parquet com partiÃ§Ã£o diÃ¡ria | `s3://<bucket>/raw/` em Parquet particionado por `dataproc=yyyyMMdd` |
| **R3** â€“ Bucket aciona Lambda que chama o job Glue | Evento `ObjectCreated` em `raw/` dispara Lambda |
| **R4** â€“ Lambda apenas inicia o job Glue | Lambda chama `glue:StartJobRun` do job `b3_transform` |
| **R5** â€“ Glue com transformaÃ§Ãµes obrigatÃ³rias (A/B/C) | Implementadas no `src/b3_transform.py` (detalhadas abaixo) |
| **R6** â€“ Refined em Parquet na pasta `refined/` particionado por data e ticker | `s3://<bucket>/refined/` particionado por `dataproc` e `ticker` |
| **R7** â€“ Catalogar no Glue Catalog e criar tabela | Jobs criam/atualizam tabelas no Glue Catalog + `MSCK REPAIR TABLE` |
| **R8** â€“ Consultar via SQL no Athena | Consultas em `b3_data.stocks_refined` |

---

## ğŸ—ï¸ Arquitetura

![Diagrama de Arquitetura](docs/arquitetura.png)

**Fluxo ponta a ponta:**
1. **EventBridge (agendamento)** inicia o pipeline (executa o Glue Collector).
2. **Glue Collector (`b3_collector.py`)** coleta dados (yfinance) e grava no S3 em **raw** (Parquet, partiÃ§Ã£o diÃ¡ria).
3. **S3 Event Notification** em `raw/` aciona a **Lambda**.
4. **Lambda (`glue_starter_lambda_function.py`)** apenas inicia o Glue Transform.
5. **Glue Transform (`b3_transform.py`)** lÃª `raw/`, aplica A/B/C e grava em **refined** (Parquet, partiÃ§Ã£o por `dataproc` e `ticker`).
6. **Glue Data Catalog** Ã© atualizado e as partiÃ§Ãµes sÃ£o descobertas.
7. **Athena** consulta os dados refinados via SQL.

---

## ğŸª£ Data Lake no S3 (raw/refined)

> No ambiente de teste, usamos o bucket: `tc2-carol-224328871288` (o nome pode variar por conta).

### Raw (R2)
- **Path:** `s3://<bucket>/raw/`
- **Formato:** Parquet (SNAPPY)
- **PartiÃ§Ã£o:** `dataproc=yyyyMMdd`

Exemplo:
- `s3://<bucket>/raw/dataproc=20260120/part-000.parquet`

### Refined (R6)
- **Path:** `s3://<bucket>/refined/`
- **Formato:** Parquet (SNAPPY)
- **PartiÃ§Ãµes:** `dataproc=yyyyMMdd` e `ticker=<CODIGO>`

Exemplo:
- `s3://<bucket>/refined/dataproc=20260120/ticker=PETR4/part-000.parquet`

---

## ğŸ§¾ Schema (visÃ£o geral)

### Raw (saÃ­da do Collector)
Colunas principais:
- `date`, `open`, `high`, `low`, `close`, `volume`, `dividends`, `stock-splits`, `ticker`
- `dataproc` (**partiÃ§Ã£o**, string `yyyyMMdd`)

### Refined (saÃ­da do Transform)
AlÃ©m das colunas do raw, inclui:
- `preco_fechamento` (**renomeada**)
- `volume_negociado` (**renomeada**)
- `year`, `month` (derivadas de `date`)
- `preco_7d_atras`, `preco_30d_atras`
- `variacao_7d`, `variacao_30d`

---

## ğŸ”„ TransformaÃ§Ãµes obrigatÃ³rias (R5) â€” A/B/C

As transformaÃ§Ãµes foram implementadas no Glue Transform (`src/b3_transform.py`):

### **B) Renomear duas colunas**
- `close` â†’ `preco_fechamento`
- `volume` â†’ `volume_negociado`

### **C) CÃ¡lculo baseado em data (diferenÃ§a entre perÃ­odos)**
CÃ¡lculo de variaÃ§Ã£o percentual do preÃ§o de fechamento em relaÃ§Ã£o a:
- **7 dias atrÃ¡s** (`variacao_7d`)
- **30 dias atrÃ¡s** (`variacao_30d`)

FÃ³rmula:
`((preco_atual - preco_anterior) / preco_anterior) * 100`

ImplementaÃ§Ã£o:
- Janela por `ticker` ordenada por `date` (`Window.partitionBy("ticker").orderBy("date")`)
- `lag()` de 7 e 30 linhas + tratamento de nulos

### **A) Agrupamento numÃ©rico + sumarizaÃ§Ã£o/contagem/soma**
SumarizaÃ§Ã£o mensal por `ticker`, `year` e `month` com:
- `count(*)` â†’ `total_registros`
- `sum(volume_negociado)` â†’ `volume_total_mes`
- `avg(preco_fechamento)` â†’ `preco_medio_mes`
- `min(preco_fechamento)` e `max(preco_fechamento)`
- mÃ©dias de `variacao_7d` e `variacao_30d`

> O job tambÃ©m registra no log exemplos de agregaÃ§Ã£o, facilitando a validaÃ§Ã£o.

---

## ğŸ—‚ï¸ Glue Catalog e Athena (R7/R8)

Tabelas externas criadas/atualizadas no Glue Data Catalog:
- **Raw:** `b3_data.stocks`
- **Refined:** `b3_data.stocks_refined`

As partiÃ§Ãµes sÃ£o descobertas com:
- `MSCK REPAIR TABLE b3_data.stocks;`
- `MSCK REPAIR TABLE b3_data.stocks_refined;`

### Consultas de exemplo (Athena)
```sql
-- Preview refined
SELECT * FROM b3_data.stocks_refined LIMIT 10;

-- Consulta por partiÃ§Ã£o (mais barata e rÃ¡pida)
SELECT date, ticker, preco_fechamento, volume_negociado, variacao_7d, variacao_30d
FROM b3_data.stocks_refined
WHERE dataproc = 'YYYYMMDD' AND ticker = 'PETR4'
ORDER BY date;

-- SumarizaÃ§Ã£o mensal (Requisito A)
SELECT ticker, year, month,
       COUNT(*) AS total_registros,
       SUM(volume_negociado) AS volume_total_mes,
       ROUND(AVG(preco_fechamento), 2) AS preco_medio_mes
FROM b3_data.stocks_refined
GROUP BY ticker, year, month
ORDER BY ticker, year, month;
'###

# ğŸ“ Estrutura do repositÃ³rio
.
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ arquitetura.png
â”œâ”€â”€ infra/                         # Terraform (opcional, quando aplicÃ¡vel)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ b3_collector.py
â”‚   â”œâ”€â”€ b3_transform.py
â”‚   â””â”€â”€ glue_starter_lambda_function.py
â””â”€â”€ README.md

# ğŸ§° Tecnologias

Terraform (IaC)
AWS Glue (PySpark)
AWS Lambda
Amazon S3
AWS Glue Data Catalog
Amazon Athena
Amazon EventBridge
Python / Pandas / yfinance / boto3

# ğŸ‘¥ Equipe

Hugo de Almeida Ribeiro
Matheus de Oliveira Silvestre
Carolina Devens Rabelo
Francisco Valterlan de Oliveira Dantas
